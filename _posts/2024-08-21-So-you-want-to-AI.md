---
title: "So you want to AI"
date: 2024-08-21
---

There is a lot of funding being diverted to AI, many papers published on AI, and almost every graduate student wants to work on AI. It might not be the healthiest situation for AI, machine learning, or computer science.

I saw an interaction on reddit where someone asked chatgpt to count the number of Rs in the word strawberry. Not only was it hilarious, but it was reproducible with copilot, and it made so many different kinds of mistakes:

![Asking Copilot how many Rs are in raspberry](https://dkifer.github.io/blog/docs/assets/images/r1.jpg)
![Convincing Copilot it was wrong](https://dkifer.github.io/blog/docs/assets/images/r2.jpg)
![Checking copilot with raspberry and raspberries](https://dkifer.github.io/blog/docs/assets/images/r3.jpg)

**But maybe AI can help generate images for a class I am teaching?**

![Asking copilot to generate an image without people. There were lots of people in the images anyway.](https://dkifer.github.io/blog/docs/assets/images/aiimage.jpg)

So what is the punchline? Be objective and don't let hype influence your decisions.

Disclaimers: 
- Deep learning is a great tool if you understand the implications of the universal approximation theorems (more on that in the future).
- Being able to use tensorflow and pytorch are crucial programming skills. But that doesn't mean you have to (or need to) do research in AI or machine learning. There are many other important/useful fields in computer science in which research is a rewarding experience.
- I use copilot frequently to summarize answers to a question that can be found on the web. I don't trust the answer but it is a good starting point for digging deeper into a question.
- I was hoping to use copilot/dall-e to generate pictures I could use in slides, but the amount of prompting needed takes so much time, that it is better spent in following online drawing tutorials to build skills and then drawing images myself.
